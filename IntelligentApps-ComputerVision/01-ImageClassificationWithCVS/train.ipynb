{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Part 1: Train, evaluate, and test\n\nIn this part of the lab you will use Custom Vision Python SDK to train, evaluate, fine tune, and test the custom image classification model described in the introduction."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Lab setup\n\nBefore proceeding with the lab you need to install Custom Vision Service SDK into your notebook's kernel."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Install Custom Vision Service SDK"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Install Custom Vision Service SDK  in the current Jupyter kernel\nimport sys\n!{sys.executable} -m pip install azure-cognitiveservices-vision-customvision",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Get the training and prediction keys\n\nTo invoke Custom Vision API you will need access keys.\n\nTo get the keys, navigate to the resource group you created during the lab setup and retrieve the keys for both training and prediction services. The keys can be grabbed from the overview page of each service."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\nfrom azure.cognitiveservices.vision.customvision.training.models import ImageUrlCreateEntry\n\nENDPOINT = \"https://southcentralus.api.cognitive.microsoft.com\"\n\n# update keys\ntraining_key = ''\nprediction_key = ''\n\ntrainer = CustomVisionTrainingClient(training_key, endpoint=ENDPOINT)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a Custom Vision Service project\n\nA Custom Vision Service project is a container for the artifacts used during model development, including training data and training runs. You have to create a seperate project for each model you want to develop."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Choose the name for your project\nproject_name = 'AerialClassifier'\n\n# Check if the project with that name exists\nproject_id = None\nfor project in trainer.get_projects():\n    if project.name == project_name:\n        project_id = project.id\n        print(\"Found existing project: {0}\".format(project_id))\n        break\n# Create a new project        \nif project_id == None:\n    print(\"Creating a new project\")\n    project = trainer.create_project(project_name)\n    project_id = project.id\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prepare data\nAs described in the intro to the lab, you will train the model on ~500 images representing 3 types of land: `Barren`, `Cultivated`, and `Developed`.\n\nThe training images can be uploaded from the public Azure blob container."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Get example images\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh\nwget -nv https://azureailabs.blob.core.windows.net/aerialsamples/aerial.zip\nunzip aerial.zip",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Add tags to your project\nYou need to add tags to your project before you can label and upload your training images.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create tags. Check for existing tags before creating new ones\ntags = trainer.get_tags(project_id)\nif len(tags) == 0:\n    tags = [trainer.create_tag(project_id, tag) for tag in ['Barren', 'Developed', 'Cultivated']]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Tag and upload images\n\nThe API used to upload images `create_images_from_files` uploads a batch of images at a time. The maximum supported batch size is 64. To simplify the upload process we created a utility function `upload_images` that manages batch creation and upload.\n\nThe input to the function is the list of Python tuples, where each tuple represents a single image and consists of the Tag ID (that refers to the tag describing the image) and the path to the image on your local file system. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n\n# Define a utility function to upload a list of images\ndef upload_images(training_key, project_id, image_list, batch_size=64):    \n    ENDPOINT = \"https://southcentralus.api.cognitive.microsoft.com\"\n    trainer = CustomVisionTrainingClient(training_key, endpoint=ENDPOINT)\n    print(\"Starting upload ...\")\n    image_batches = [image_list[start: start+batch_size] for start in range(0, len(image_list), batch_size)]\n    for batch in image_batches:\n        image_entry_batch = []\n        for tag, pathname, file_name in batch:\n            with open(pathname, mode='rb') as image_contents:\n                image_entry_batch.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), tag_ids=[tag]))\n        summary = trainer.create_images_from_files(project_id, images=image_entry_batch)\n    print(\"Done.\")\n    return summary\n\n\n# Upload images\nbase_folder = 'aerial/train'\n# Create a dictionary mapping tag names to tag ids\ntag_map = {tag.name: tag.id for tag in tags}\n# Create an input list to upload_images function\nimage_list = [(tag_map[folder], os.path.join(base_folder, folder, filename), filename)  for folder in ['Barren','Cultivated', 'Developed'] for filename in os.listdir(os.path.join(base_folder, folder))]\n# Start the upload\nsummary = upload_images(training_key, project_id, image_list, batch_size = 64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Train the first iteration of the project\n\nYou will repeat the training a couple of times during the lab. To simplify the process we created a helper function that encapsulates training steps."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import time\n\ndef train(training_key, project_id):\n    trainer = CustomVisionTrainingClient(training_key, endpoint=ENDPOINT)\n    print(\"Starting training...\")\n    try:\n        iteration = trainer.train_project(project_id)\n        while (iteration.status != \"Completed\"):\n            time.sleep(5)\n            iteration = trainer.get_iteration(project_id, iteration.id)\n            print (\"Training status: \" + iteration.status)      \n        # The iteration is now trained. Make it the default project endpoint\n        print(\"Training completed\")\n        trainer.update_iteration(project_id, iteration.id, is_default=True)\n    except:\n        print(\"No need to retrain. Retrieving default iteration\")\n        for iteration in trainer.get_iterations(project_id):\n            if iteration.is_default:\n                break\n\n    return iteration.id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Every time you invoke training a new iteration is created. An iteration is a Custom Vision Service object that encapsulates training data, trained model, and performance measures for a  training run."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Start training\niteration_id = train(training_key, project_id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Get iteration performance \n\nAfter the training run has completed, you can retrieve perfomance measures for the iteration. We defined a helper function `display_iteration_performance` that encapsulates the call to the service and formatting of the ouput."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def display_iteration_performance(training_key, project_id, iteration_id):\n    trainer = CustomVisionTrainingClient(training_key, endpoint=ENDPOINT)\n    performance = trainer.get_iteration_performance(project_id, iteration_id)\n    print(\"Overall Precision: {0:<10}\".format(performance.precision))\n    print(\"Overall Recall:    {0:<10}\".format(performance.recall))\n    for tag_perf in performance.per_tag_performance:\n        print(\"Tag: {0:<15} Precision: {1:<10}   Recall: {2:<10}\".format(tag_perf.name, tag_perf.precision, tag_perf.recall))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "display_iteration_performance(training_key, project_id, iteration_id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Improve your classifier\n\nThe quality of your classifier is dependent on the amount, quality, and variety of the labeled data you provide to it and how balanced the dataset is. A good classifier normally has a balanced training dataset that is representative of what will be submitted to the classifier. The process of building such a classifier is \niterative. It's common to take a few rounds of training to reach expected results. As you track the performance of your model you may add more images of the underperforming class or augment your existing images by varying lighting, cropping, color saturation, etc.\n\nIn the next step you will add more images of  `Developed`  land plots and retrain the model to create the new iteration."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Upload images\nbase_folder = 'aerial/train'\nfolder = 'Developed-SecondBatch'\nimage_list = [(tag_map['Developed'], os.path.join(base_folder, folder, filename), filename)  for filename in os.listdir(os.path.join(base_folder, folder))]\n\nsummary = upload_images(training_key, project_id, image_list, batch_size = 64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Re-train the project.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Start training\niteration_id = train(training_key, project_id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "display_iteration_performance(training_key, project_id, iteration_id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Test\n\nYour model is ready. Each time you run training, Custom Vision Service automatically creates a REST API wrapper - prediction endpoint - around the model created by a training run. You can use it immediately after the run has completed."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Download test images"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh\nmkdir test_images\ncd test_images\nwget -nv https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/barren-1.png\nwget -nv https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/cultivated-1.png\nwget -nv https://github.com/jakazmie/AIDays/raw/master/DeveloperTrack/01-CustomVisionService/samples/developed-1.png",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Display test images\n\nThe images we will use for testing have been downloaded to the `test_imags` folder."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimages_dir = 'test_images'\nimages = [os.path.join(images_dir, file) for file in os.listdir(images_dir)]\n\nfigsize=(10, 8)\nfig, axis = plt.subplots(len(images)//3, 3, figsize=figsize)\nfig.tight_layout()\nfor ax, image_path in zip(axis.flat[0:], images):\n    image = Image.open(image_path)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    ax.imshow(image)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": " ### Test with `curl`\n \n As noted, the prediction endpoint is a REST API that can be accessed using any tool capable of formatting REST requests, including a command line tool `curl`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%env PROJECT_ID=$project_id\n%env PREDICTION_KEY=$prediction_key",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%sh\n\ncurl -X POST https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/$PROJECT_ID/image -H \"Prediction-Key: $PREDICTION_KEY\"  -H \"Content-Type: application/octet-stream\" --data-binary @test_images/developed-1.png",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Call the prediction endpoint using Python SDK\n\nFrom Python, you can invoke the prediction endpoint using `urllib` or other library for working with HTTP. However, it is even easier to use Custom Vision Service Python SDK.\n\nPython SDK wraps the prediction endpoint in the `prediction_endpoint` class. The class exposes the `predict_image` method that takes a Python File Object as parameter. The following code snippet defines a utility function `classify_image` that invokes the prediction endpoint and parses the results returned from the service."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n\ndef classify_image(project_id, prediction_key, image_path):\n    ENDPOINT = \"https://southcentralus.api.cognitive.microsoft.com\"\n    predictor = CustomVisionPredictionClient(prediction_key, endpoint=ENDPOINT)\n    with open(image_path, mode='rb') as image:\n      result = predictor.predict_image(project_id, image)    \n    probs = [prediction.probability for prediction in result.predictions]\n    max_prob = max(probs)\n    max_index = probs.index(max_prob)\n    tag = result.predictions[max_index].tag_name\n\n    return tag, max_prob",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You will now invoke the prediction endpoint and display the results returned by the service."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "figsize=(10, 8)\nfig, axis = plt.subplots(len(images)//3, 3, figsize=figsize)\nfig.tight_layout()\nfor ax, image_path in zip(axis.flat[0:], images):\n    tag, prob = classify_image(project_id, prediction_key, image_path)\n    ax.set_title(tag + ': ' + str(prob))\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    image = Image.open(image_path)\n    ax.imshow(image)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Summary\n\nIn this part of the lab you learned how to train, evaluate and improve your custom image classification model. In the second part of the lab, you will learn how to export and operationalize your trained model.\n\nTo proceed to Part II, open `export.ipynb` notebook."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}